{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038195c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract entity data from the original dataset\n",
    "import re\n",
    "import pandas as pd\n",
    "metric=[]\n",
    "\n",
    "with open('.Dataset/ent-text-79-22.txt', mode='r', encoding='utf-8') as f:\n",
    "\n",
    "    lines = f.readlines()\n",
    "    ent_lists=[]\n",
    "    for idx, line in enumerate(lines):\n",
    "        if idx%1000==0:\n",
    "            print(idx)\n",
    "        ents = re.findall(r\"<entity_(Metric|Method|Dataset|Tool)>(.*?)</entity_(Metric|Method|Dataset|Tool)>\", line)\n",
    "\n",
    "        ent_list = []\n",
    "        for e in ents:\n",
    "\n",
    "            ent_list.append([e[0].lower(), e[1].lower()])\n",
    "        str(ent_list)\n",
    "        ent_lists.append(str(ent_list))\n",
    "with open('./initial_entitydata/id.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(ent_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract basic information\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "f = open(r\"./initial_entitydata/ent-text-79-22.txt\" ,encoding='utf-8')\n",
    "file_content =f.read()\n",
    "\n",
    "\n",
    "l_id = re.findall(r'\"id\":(.+?),' ,file_content)\n",
    "l_year = re.findall(r'\"year\":(.+?),' ,file_content)\n",
    "l_title = re.findall(r'\"title\":(.+?),' ,file_content)\n",
    "\n",
    "all_info =[]\n",
    "for i in range(len(l_id)):\n",
    "    each_info ={}\n",
    "    each_info['id' ] =l_id[i]\n",
    "    each_info['year' ] =l_year[i]\n",
    "    each_info['title' ] =l_title[i]\n",
    "    all_info.append(each_info)\n",
    "\n",
    "df1 =pd.DataFrame(all_info)\n",
    "df1.to_excel(r'base_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a table of entity frequencies\n",
    "import  json\n",
    "from collections import Counter, defaultdict\n",
    "all_ent=[]\n",
    "d = defaultdict(int)\n",
    "with open('./initial_entitydata/ent_ent.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        entity=eval(line)\n",
    "        for ent in entity:\n",
    "            d[ent[1]] += 1\n",
    "ent2id = {}\n",
    "\n",
    "result_sorted = sorted(d.items(),key = lambda x:x[1], reverse = True)\n",
    "m=0\n",
    "for i in result_sorted:\n",
    "   ent2id[i[0]]=m\n",
    "   m+=1\n",
    "with open('./ent2id/ent2id.txt', 'w', encoding='utf8') as f:\n",
    "    json.dump(ent2id, f, indent=4)\n",
    "\n",
    "res = []\n",
    "for i in result_sorted:\n",
    "    res.append(f'{i[0]}\\t{i[1]}')\n",
    "\n",
    "with open('./ee/ee.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "#The load_model function in the import fasttext module is used to import the pre-trained ftt.model\n",
    "from fasttext import load_model\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "\n",
    "\n",
    "def get_vec(path, model_path):\n",
    "    ftt_model = load_model(model_path)\n",
    "    ents = []\n",
    "    vecs=[]\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        content = f.read()\n",
    "        dictionary = eval(content)\n",
    "        for key in dictionary:\n",
    "           id=dictionary[key]\n",
    "           v=ftt_model.get_word_vector(key)\n",
    "           v = list(v)\n",
    "           v.insert(0, id)\n",
    "           v = map(str, v)\n",
    "           vecs.append(' '.join(v))\n",
    "\n",
    "           if len(vecs)==10000:\n",
    "               with open('./vecs/vecs.txt', 'a', encoding='utf8') as f:\n",
    "                   f.write('\\n'.join(vecs)+'\\n')\n",
    "                   vecs = []\n",
    "                   print(id + 1)\n",
    "\n",
    "        if vecs:\n",
    "            with open('./vecs/vecs.txt', 'a', encoding='utf8') as f:\n",
    "                f.write('\\n'.join(vecs) + '\\n')\n",
    "            print(id + 1)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    get_vec(\"./ent2id/ent2id.txt\",\"ftt.model\")\n",
    "    model = KeyedVectors.load_word2vec_format(\"./vecs/vecs.txt\", binary=False, no_header=True)\n",
    "    model.save_word2vec_format(\"./vecs/vecs.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85087e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codify the initial paper entity\n",
    "import re\n",
    "import pandas\n",
    "restr = r\"[\\@()/.\\w\\s\\-]+\"\n",
    "entityset = set(['method', 'dataset', 'tool', 'metric', ' '])\n",
    "ent2id = json.loads(open('./ent2id/ent2id.txt', 'r', encoding='gbk').read())\n",
    "entity=[]\n",
    "lengths=[]\n",
    "def entid_match(entity):\n",
    "    id = []\n",
    "    for ety in entity:\n",
    "        if ety[1] in ent2id:\n",
    "            id.append(ent2id[ety[1]])\n",
    "    id=list(set(id))\n",
    "    id.sort(reverse=False)\n",
    "    return id\n",
    "entid = {}\n",
    "df = pd.DataFrame(columns=[\"Lists\"])\n",
    "entid={}\n",
    "with open('./initial_entitydata/ent_lists.txt', mode='r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        entity=eval(line)\n",
    "        lst = entid_match(entity)\n",
    "        df.loc[len(df)] = [lst]\n",
    "\n",
    "df.to_excel('./id2id/initialenttoid.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novel combinations of entities\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.read_excel('./id2id/initialenttoid_tool.xlsx')\n",
    "ids=df[df.columns[1]].tolist()\n",
    "model = KeyedVectors.load_word2vec_format('./vecs/vecs_tool.bin', binary=True, unicode_errors='ignore')\n",
    "\n",
    "res, i = [], 0\n",
    "\n",
    "for k in ids:\n",
    "    i += 1\n",
    "    ids=eval(k)\n",
    "    ids = sorted(ids)\n",
    "    if len(ids)<1: continue\n",
    "    combs = combinations(ids, 2)\n",
    "    for c in combs:\n",
    "        sim = model.similarity(str(c[0]), str(c[1]))\n",
    "        res.append(f'{c[0]}-{c[1]}\\t{sim}')\n",
    "    if i%500==0:\n",
    "        with open('./sims/sims.txt', 'a', encoding='utf8') as f:\n",
    "            f.write('\\n'.join(res)+'\\n')\n",
    "        res = []\n",
    "        print(i)\n",
    "if res:\n",
    "    with open('./sims/sims.txt', 'a', encoding='utf8') as f:\n",
    "        f.write('\\n'.join(res))\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1659b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novelty Score Measure\n",
    "import json\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "df=pd.read_excel('./id2id/initialenttoid.xlsx')\n",
    "ids=df[df.columns[1]].tolist()\n",
    "ent2=[]\n",
    "with open('./sims/sims.txt',encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        a=line.split('\\t')\n",
    "\n",
    "        ent2.append(a[0])\n",
    "    # print(ent2)\n",
    "index =int( len(ent2) )\n",
    "\n",
    "# ent3=set(ent2[:index])\n",
    "# print(len(ent3))\n",
    "ent2.sort(key=lambda x: x[1])\n",
    "ent3=ent2[:int(index*0.1)]\n",
    "print(ent3)\n",
    "i=0\n",
    "score={}\n",
    "for id in ids:\n",
    "    i += 1\n",
    "    id = eval(id)\n",
    "    if len(id)<2:\n",
    "        novelty=0\n",
    "        score[i] = novelty\n",
    "    else:\n",
    "        combs = combinations(id, 2)\n",
    "        n, l =0, 0\n",
    "        for c in combs:\n",
    "            l += 1\n",
    "            if f'{c[0]}-{c[1]}' in ent3:\n",
    "                n+=1\n",
    "        novelty=n/l\n",
    "        score[i]=novelty\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "\n",
    "with open('score.txt', 'w', encoding='utf-8') as file:\n",
    "    json.dump(score, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
